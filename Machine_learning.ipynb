{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install google-cloud-sdk\n",
    "pip install google-cloud-vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import vision_v1\n",
    "from google.cloud.vision_v1 import types\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'path/to/credentials.json'\n",
    "client = vision_v1.ImageAnnotatorClient()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('path/to/IELTS-template.jpg', 'rb') as image_file:\n",
    "    content = image_file.read()\n",
    "\n",
    "image = types.Image(content=content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.text_detection(image=image)\n",
    "texts = response.text_annotations\n",
    "\n",
    "for text in texts:\n",
    "    print(text.description)\n",
    "    vertices = [(vertex.x, vertex.y) for vertex in text.bounding_poly.vertices]\n",
    "    print(vertices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.face_detection(image=image)\n",
    "faces = response.face_annotations\n",
    "\n",
    "for face in faces:\n",
    "    print('Joy Likelihood: {}'.format(face.joy_likelihood))\n",
    "    print('Sorrow Likelihood: {}'.format(face.sorrow_likelihood))\n",
    "    print('Anger Likelihood: {}'.format(face.anger_likelihood))\n",
    "    print('Surprise Likelihood: {}'.format(face.surprise_likelihood))\n",
    "    vertices = [(vertex.x, vertex.y) for vertex in face.bounding_poly.vertices]\n",
    "    print(vertices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision import types\n",
    "\n",
    "# Set up credentials\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'path/to/service_account_key.json'\n",
    "\n",
    "# Create a Vision API client\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "# Load the image file\n",
    "with io.open('path/to/IELTS-template.jpg', 'rb') as image_file:\n",
    "    content = image_file.read()\n",
    "\n",
    "# Create an image instance and annotate it\n",
    "image = types.Image(content=content)\n",
    "response = client.annotate_image({\n",
    "    'image': image,\n",
    "    'features': [{'type': vision.enums.Feature.Type.TEXT_DETECTION}]\n",
    "})\n",
    "\n",
    "# Extract the text from the response\n",
    "text = response.text_annotations[0].description\n",
    "print(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
